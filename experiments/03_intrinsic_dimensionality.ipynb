{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from representations_across_sizes.gride import calculate_gride_id, get_sequences\n",
    "import torch\n",
    "\n",
    "sequences_pile = get_sequences(dataset_name=\"pile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sequences_pile[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_pile_debug = sequences_pile[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_pile_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lm.model.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "from representations_across_sizes.utils import get_activation_cache\n",
    "\n",
    "model = \"meta-llama/Llama-3.2-1B\"\n",
    "lm = LanguageModel(model, device_map=\"auto\")\n",
    "remote = False\n",
    "\n",
    "activations = get_activation_cache(lm, layer_idxs=list(range(len(lm.model.layers))), dataset=sequences_pile_debug, llm_batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lovely_tensors import monkey_patch\n",
    "monkey_patch()\n",
    "activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from torch import Tensor\n",
    "\n",
    "# get only the last sequence, and cat into one tensor\n",
    "for layer, acts in activations.items():\n",
    "    acts: List[Tensor] = [act[:, -1, :] for act in acts]\n",
    "    activations[layer] = torch.cat(acts, dim=0)\n",
    "\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from representations_across_sizes.gride import calculate_gride_id\n",
    "\n",
    "ids = [float(calculate_gride_id(activations[layer].to('cpu'))) for layer in activations.keys()]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(ids, marker='o', label='llama', color='#1f77b4')  # Using the same blue as in reference\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Average ID over Layers\")\n",
    "plt.xlabel(\"layer\")\n",
    "plt.ylabel(\"intrinsic dimension\")\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Set y-axis limits similar to reference plot\n",
    "plt.ylim(5, 45)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for many models over all partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# use all partitions\n",
    "sequences_pile = get_sequences(dataset_name=\"pile\")\n",
    "\n",
    "# Store IDs for each partition\n",
    "all_partition_ids = []\n",
    "\n",
    "for partition in sequences_pile:\n",
    "\n",
    "    print(f\"Processing partition {len(all_partition_ids)+1}/5\")\n",
    "    \n",
    "    # Get activations for this partition\n",
    "    activations = get_activation_cache(\n",
    "        lm, \n",
    "        layer_idxs=list(range(len(lm.model.layers))), \n",
    "        dataset=partition, \n",
    "        llm_batch_size=64\n",
    "    )\n",
    "    \n",
    "    # Get only the last sequence token and calculate IDs\n",
    "    for layer, acts in activations.items():\n",
    "        acts = [act[:, -1, :] for act in acts]\n",
    "        activations[layer] = torch.cat(acts, dim=0)\n",
    "    \n",
    "    # Calculate IDs for this partition\n",
    "    partition_ids = [float(calculate_gride_id(activations[layer].to('cpu'))) \n",
    "                    for layer in activations.keys()]\n",
    "    all_partition_ids.append(partition_ids)\n",
    "    print(partition_ids)\n",
    "\n",
    "# Convert to numpy for easier calculations\n",
    "all_partition_ids = np.array(all_partition_ids)\n",
    "\n",
    "# Calculate mean and std across partitions\n",
    "mean_ids = np.mean(all_partition_ids, axis=0)\n",
    "std_ids = np.std(all_partition_ids, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_partition_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_partition_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_partition_ids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_partition_ids[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_partition_ids[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot with error bars\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.errorbar(\n",
    "    range(len(mean_ids)), \n",
    "    mean_ids,\n",
    "    yerr=2*std_ids,  # 2 standard deviations like in paper\n",
    "    fmt='o-',\n",
    "    label='llama',\n",
    "    color='#1f77b4',\n",
    "    capsize=3,\n",
    "    markersize=4,\n",
    "    linewidth=1,\n",
    "    elinewidth=1\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Average ID over Layers\")\n",
    "plt.xlabel(\"layer\")\n",
    "plt.ylabel(\"intrinsic dimension\")\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Set y-axis limits similar to reference plot\n",
    "plt.ylim(5, 45)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
